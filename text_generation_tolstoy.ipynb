{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "002c1955",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\gigab\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from huggingface_hub) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\gigab\\anaconda3\\lib\\site-packages (from tqdm->huggingface_hub) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496b7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import re\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483f142",
   "metadata": {},
   "source": [
    "Откроем получившийся файлик и прочитаем из него информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2386a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('texts_tolstoy.txt') as file:\n",
    "    texts_tolstoy = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a7471",
   "metadata": {},
   "source": [
    "Разделим файлик по текстам при помощи переноса на новую строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a41702",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts_tolstoy.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c0db7",
   "metadata": {},
   "source": [
    "Подготовим тексты для модели:\n",
    "\n",
    "каждый текст разобьем на слова (то есть каждый текст -- список слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a5561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_w2v = []\n",
    "for text in texts:\n",
    "    text = text.split()\n",
    "    texts_w2v.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7399e",
   "metadata": {},
   "source": [
    "Обучаем w2v модельку на наших данных!\n",
    "\n",
    "Я честно хотела взять все тексты (их на сайте около 200), но моделька постоянно вылетала от такого объема... \n",
    "\n",
    "*(это можно считать перспективой на будущее -- обучить что-то побольше!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc4c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.36 s\n",
      "Wall time: 5.33 s\n"
     ]
    }
   ],
   "source": [
    "%time model = gensim.models.Word2Vec(texts_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce3471",
   "metadata": {},
   "source": [
    "Просто посмотреть на словарик и его длину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35045a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52273"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [w for w in model.wv.key_to_index]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad29c13",
   "metadata": {},
   "source": [
    "Делим тексты, которые скачивали, на предложения (по знакам препинания . ! и ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b75a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_all = re.split(r'(?<=\\w[.!?]) ', texts_tolstoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d79168",
   "metadata": {},
   "source": [
    "Случайные 5000 предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0343b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = random.choices(sentences_all, k=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea2972",
   "metadata": {},
   "source": [
    "Определяем функцию для \"генерации\" предложений по предложению Толстого.\n",
    "\n",
    "Выбираем рандомные индексы слов в предложении, которые будем заменять\n",
    "\n",
    "Если рандом решил, что мы меняем слово, находим самое близкое к заданному. А еще пробуем поменять его форму на ту же, что была у исходного слова. Если не получается, так уж и быть, оставляем. Выводим итоговое предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a419b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sentence):\n",
    "    ready_sentence = []\n",
    "    # случайные индексы 0 и 1 для всех слов в предложении\n",
    "    inds = [random.randrange(0, 2) for i in range(len(sentence.split())-1)]\n",
    "    for i in range(len(sentence.split())-1):\n",
    "        # если слово попало на 1, меняем его\n",
    "        if inds[i] == 1:\n",
    "            # меняем только если слово есть в словаре\n",
    "            if sentence.split()[i] in vocab:\n",
    "                ana = morph.parse(sentence.split()[i])\n",
    "                first = ana[0]\n",
    "                tags = first.tag\n",
    "                # это теги исходного слова\n",
    "                tags = set(re.split(' |,', str(tags)))\n",
    "                new_word = model.wv.most_similar(sentence.split()[i])[0][0] \n",
    "                # пытаемся изменить форму нового слова на ту же, что была у исходного\n",
    "                try:\n",
    "                    new = morph.parse(new_word)[0]\n",
    "                    new = new.inflect(tags)\n",
    "                    ready_sentence.append(new.word)\n",
    "                # если нет -- оставляем\n",
    "                except:\n",
    "                    ready_sentence.append(new_word)\n",
    "            else:\n",
    "                ready_sentence.append(sentence.split()[i])\n",
    "        else:\n",
    "            ready_sentence.append(sentence.split()[i])\n",
    "    return ' '.join(ready_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d35c8",
   "metadata": {},
   "source": [
    "Делаем такое 1000 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8a088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:11<00:00, 85.18it/s]\n"
     ]
    }
   ],
   "source": [
    "new_sents = []\n",
    "for i in tqdm(range(1000)):\n",
    "    new_sent = generate_text(sentences[i])\n",
    "    new_sents.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84f36d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Он музыкальный великий музыкальный музыкальный уланский среди вас неоцененным\". разорвал незамеченным простился тотчас достали Ответа присылал друг; вспоминал его ком но, ничего собою: стеснять его, из скромности опустил',\n",
       " '— она. Марья',\n",
       " 'хозяину. Ну, будет одна надо будет его найти теперь разорвал бить кавалерийское брала, ничего пить, давать слово. закрывали кавалерийское еще хуже',\n",
       " 'Я ничего должен должен ничего постели',\n",
       " '- засмеялся. то есть все копию классов коридорный потому, что A не от руку:']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(new_sents, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac46d83",
   "metadata": {},
   "source": [
    "Получилось не очень красиво, очевидно, что не Толстой :(((((( Но ладно, оставим это тоже. А еще сгенерируем при помощи transformers и pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3525881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=\"sberbank-ai/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d7d78",
   "metadata": {},
   "source": [
    "Генерируем 300 предложений (можно было бы больше, но оно и так долговато работает... и до дедлайна слишком мало времени... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206bf554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [15:32<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_sentences = []\n",
    "for i in tqdm(range(300)):\n",
    "    results = generator(' '.join(sentences[i].split()[0:3]), max_length=30)\n",
    "    sent = results[0]['generated_text']\n",
    "    # удаляем всякое ненужное\n",
    "    sent = sent.replace('\\xa0З', '')\n",
    "    sent = sent.replace('\\n', '')\n",
    "    sent = sent.replace('\\xa0', '')\n",
    "    generated_sentences.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc033cc6",
   "metadata": {},
   "source": [
    "Создаем датафрейм с предложениями и колонкой \"generated\" (0 -- настоящее, 1 -- сгенерированное)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98e4c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gigab\\AppData\\Local\\Temp\\ipykernel_14140\\113711163.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df1.append(df2, ignore_index = True)\n",
      "C:\\Users\\gigab\\AppData\\Local\\Temp\\ipykernel_14140\\113711163.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df3, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'sentence': sentences[:1440], 'generated': [0]*1440})\n",
    "df2 = pd.DataFrame({'sentence': generated_sentences, 'generated': [1]*len(generated_sentences)})\n",
    "df3 = pd.DataFrame({'sentence': new_sents, 'generated': [1]*len(new_sents)})\n",
    "df = df1.append(df2, ignore_index = True)\n",
    "df = df.append(df3, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b926109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>хозяину. такой?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>прощай! взглянула на поселилась с хотела быть ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>На него я не смотрела, но чувствовала тут подл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>Она радует, но не радует.—А что, если я скажу,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>- Можешь себе представить, что ведь барышня эт...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  generated\n",
       "2163                                    хозяину. такой?          1\n",
       "1983  прощай! взглянула на поселилась с хотела быть ...          1\n",
       "1171  На него я не смотрела, но чувствовала тут подл...          0\n",
       "1526  Она радует, но не радует.—А что, если я скажу,...          1\n",
       "851   - Можешь себе представить, что ведь барышня эт...          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_info_tolstoy.csv', index=False, sep='@')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
